{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Familiar with ML Basics in a Kaggle Competition: Titanic\n",
    "\n",
    "<img src=\"images/titanic.jpeg\" width=\"800\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 1: Getting Started with Kaggle\n",
    "    Creating your account and joining the competition\n",
    "---\n",
    "- Create your kaggle account and join the [**Titanic: Machine Learning from Disaster**](https://www.kaggle.com/c/titanic).\n",
    "- Read the description and most important informations about the competition. \n",
    "- Download the entire dataset on the platform.\n",
    "Now let's start our project! Let's dive in! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 2: Exploratory Data Analysis (EDA)\n",
    "    Start working on your dataset. Import necessary libraries and and make an exploratory data analysis using pandas profilling and seaborn.\n",
    "\n",
    "\n",
    "### Importing Libraries\n",
    "---\n",
    "Import the most important libraries you will be using initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It saves us some precious time on the EDA process.\n",
    "# You also have the option to plot the data separately, \n",
    "# using the matplolib and seaborn libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export your report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command, will export your previous report into a html file. \n",
    "#report.to_file(output_file=\"dataframe_titanic_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable Notes**\n",
    "\n",
    "_pclass_: A proxy for socio-economic status (SES)\n",
    "- _1st_ = Upper\n",
    "- _2nd_ = Middle\n",
    "- _3rd_ = Lower\n",
    "\n",
    "_age_: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "_sibsp_: The dataset defines family relations in this way...\n",
    "- _Sibling_ = brother, sister, stepbrother, stepsister\n",
    "- _Spouse_ = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "\n",
    "_parch_: The dataset defines family relations in this way...\n",
    "- _Parent_ = mother, father\n",
    "- _Child_ = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 3: Preprocessing I\n",
    "    Taking care of Missing Values\n",
    "---\n",
    "\n",
    "**Important:** Missing data is information that is missing from a database and could be important for the result of an analysis. Working with a dataset with missing values is a problem of great relevance at the time of data analysis and can originate from different sources, such as failures in the collection system, problems with the integration of different sources, etc., the point is: we must be careful to avoid bias in the results we seek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescriptive statistics include those that summarize the central tendency, \\ndispersion and shape of a datasetâ€™s distribution, excluding NaN values.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Descriptive statistics include those that summarize the central tendency, \n",
    "dispersion and shape of a datasetâ€™s distribution, excluding NaN values.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visualized our entire dataset, **check the describe above or the Sample in our dataframe report**, you see that there are certain data points labeled with a `NaN`. These denote missing values. Diferent datasets encode missing values in different ways. Sometimes it may be a `9999`, other times a`0` - because real world data can be very messy!\n",
    "\n",
    "\n",
    "**The goal here is to figure out how best to process the data so our machine learning model can learn from it.**\n",
    "\n",
    "Ideally, all the features will be encoded into a numerical value of some kind.\n",
    "Itâ€™s important to understand why you need to transform categorical data. \n",
    "Some Machine Learning algorithms do not work with categorical data, that is, they do not accept this data as input. For example, algorithms like Support Vector Machine or a Linear Regression, we will meet them in the next task, only work with numerical values. In view of this limitation, we need to convert categorical variables to numerical values in this first instance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at numeric and categorical values separately:**\n",
    "\n",
    "Numerical Features: Age (Continuous), Fare (Continuous), SibSp (Discrete), Parch (Discrete)\n",
    "\n",
    "Categorical Features: Survived, Sex, Embarked, Pclass\n",
    "\n",
    "Alphanumeric Features but categorical: Ticket, Cabin\n",
    "\n",
    "In our overview report, click on the tab \"Warnings\": \n",
    "\n",
    "- Tickets and Cabin are features with a high cardinality, e some many distinc values. \n",
    "- Age and Cabin has a lot of missing values.\n",
    "- Name and ID has unique values.\n",
    "- SibSp, Parch and Fare has a lot of zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Predictions based on our report:**\n",
    "\n",
    "Sex: Females are more likely to survive.\n",
    "\n",
    "SibSp/Parch: People traveling alone are more likely to survive.\n",
    "\n",
    "Age: Young children are more likely to survive.\n",
    "\n",
    "Pclass: People of higher socioeconomic class are more likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 4: Preprocessing II\n",
    "    Encoding Categorical Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 5: Split the Train & Test datasets\n",
    "---\n",
    "\n",
    "Split the dataset into training and testing is very common, and you will do it on countless occasions. Even though in this current problem, we have our training and test csv separately, we will use this technique in our training dataset, so we can get used to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_test_split**: The first argument will be the `feature data`, the second the `target or labels`. The `test_size` keyword argument specifies what proportion of the original data is used for the test set. Lastly, the `random_state` kward sets a seed for the random number generator that splits the data into trains and test.\n",
    "\n",
    "Splitting the Training Data we will use part of our training data (22% in this case) to test the accuracy of our different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 6: Building our Machine Learning Models I\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualising the Training set results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aditional Models\n",
    "---\n",
    "\n",
    "\n",
    "If you want to test other models, and compare their performance with the two we already use. Below you find these models already declared. Feel free to also test them. Chance the cell typo for code, and run to see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 7: Submit your project on Kaggle\n",
    "---\n",
    "\n",
    "Now, we finish our model evaluate, it's time to create a submission.csv file to upload to the Kaggle competition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run our best model to predict in the test dataset, we need enconding the categorical features, as the same way that we alredy had done in the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
