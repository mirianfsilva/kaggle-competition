{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Familiar with ML Basics in a Kaggle Competition: Titanic\n",
    "\n",
    "<img src=\"images/titanic.jpg\" width=\"800\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 1: Getting Started with Kaggle\n",
    "    Creating your account and joining the competition\n",
    "---\n",
    "- Create your kaggle account and join the [**Titanic: Machine Learning from Disaster**](https://www.kaggle.com/c/titanic).\n",
    "- Read the description and most important informations about the competition. \n",
    "- Download the entire dataset on the platform.\n",
    "Now let's start our project! Let's dive in! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 2: Exploratory Data Analysis (EDA)\n",
    "    Start working on your dataset. Import necessary libraries and and make an exploratory data analysis using pandas profilling and seaborn.\n",
    "\n",
    "\n",
    "### Importing Libraries\n",
    "---\n",
    "Import the most important libraries you will be using initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Number of Training = {}'.format(train_data.shape[0]))\n",
    "print('Number of Test = {}\\n'.format(test_data.shape[0]))\n",
    "\n",
    "#target columns\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas Profiling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable Notes**\n",
    "\n",
    "_pclass_: A proxy for socio-economic status (SES)\n",
    "- _1st_ = Upper\n",
    "- _2nd_ = Middle\n",
    "- _3rd_ = Lower\n",
    "\n",
    "_age_: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "_sibsp_: The dataset defines family relations in this way...\n",
    "- _Sibling_ = brother, sister, stepbrother, stepsister\n",
    "- _Spouse_ = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "\n",
    "_parch_: The dataset defines family relations in this way...\n",
    "- _Parent_ = mother, father\n",
    "- _Child_ = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export your report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command will export your previous report into a html file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 3: Preprocessing I\n",
    "    Taking care of Missing Values\n",
    "---\n",
    "\n",
    "**Important:** Missing data is information that is missing from a database and could be important for the result of an analysis. Working with a dataset with missing values is a problem of great relevance at the time of data analysis and can originate from different sources, such as failures in the collection system, problems with the integration of different sources, etc., the point is: we must be careful to avoid bias in the results we seek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visualized our entire dataset, **check the describe above or the Sample in our dataframe report**, you see that there are certain data points labeled with a `NaN`. These denote missing values. Different datasets encode missing values in different ways. Sometimes it may be a `9999`, other times a`0` - because real world data can be very messy!\n",
    "\n",
    "\n",
    "**The goal here is to figure out how best to process the data so our machine learning model can learn from it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at numeric and categorical values separately:**\n",
    "\n",
    "Numerical Features: Age, Fare, SibSp, Parch.\n",
    "\n",
    "Categorical Features: Survived, Sex, Embarked, Pclass.\n",
    "\n",
    "Alphanumeric Features (but categorical): Ticket, Cabin.\n",
    "\n",
    "In our overview report, click on the tab \"Warnings\": \n",
    "\n",
    "- Tickets and Cabin are features with a high cardinality, and a lot of distinc values. \n",
    "- Age and Cabin has a lot of missing values.\n",
    "- Name and ID has unique values.\n",
    "- SibSp, Parch and Fare has a lot of zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many people survived?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**Feature Name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Ticket**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "See plot inside our report. Tickets vs frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**Feature Cabin**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "See plot inside our report. Cabin vs frequency of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 4: Preprocessing II\n",
    "    Taking care of Missing Values\n",
    "---\n",
    "**Feature Embarked**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Sex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 5: Preprocessing III\n",
    "    Encoding Categorical Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding\n",
    "\n",
    "Documentation: [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "**Train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 6: Split the Train & Test datasets\n",
    "---\n",
    "\n",
    "Split the dataset into training and testing is very common, and you will do it on countless occasions. Even though in this current problem, we have our training and test csv separately, we will use this technique in our training dataset, so we can get used to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_test_split**: The first argument will be the `feature data`, the second the `target or labels`. The `test_size` keyword argument specifies what proportion of the original data is used for the test set. Lastly, the `random_state` kward sets a seed for the random number generator that splits the data into trains and test.\n",
    "\n",
    "Splitting the Training Data we will use part of our training data (30% in this case) to test the accuracy of our different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 7: Building our Machine Learning Models I\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "Logistic regression measures the relationship between the categorical dependent variable _(feature)_ and one or more independent variables _(features)_ by estimating probabilities using a logistic function, which is the cumulative distribution function of logistic distribution. \n",
    "\n",
    "Reference: [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning. It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Decision trees are among the most popular machine learning algorithms given their intelligibility and simplicity\n",
    "\n",
    "Reference: [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aditional Models\n",
    "---\n",
    "\n",
    "\n",
    "If you want to test other models, and compare their performance with the two we already use. Below you find these models already declared. Feel free to also test them. Chance the cell type, `raw` for `code`, and run to see the results. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "acc_rf = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "print(\"Random Forest Accuracy\",acc_rf)\n",
    "\n",
    "\n",
    "#KNN | K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc_knn = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "print(\"K-Nearest Neighbors Accuracy\",acc_knn)\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc_svc = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "print(\"Support Vector Machine\", acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Task 8: Submit your project on Kaggle\n",
    "---\n",
    "\n",
    "Now, we finish our model evaluate, it's time to create a submission.csv file to upload to the Kaggle competition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips and Resources: \n",
    "\n",
    "- [Seaborn: Statistical Data Visualization](https://seaborn.pydata.org/index.html)\n",
    "\n",
    "- Resources that may be insterested take a look: [Titanic - A Data Science Approach](https://www.kaggle.com/pedrodematos/titanic-a-complete-data-science-approach)\n",
    "\n",
    "- This complete notebook, you will find in my github account, if you want make improvements, feel free to do that and share with me. \n",
    "[Project on Github](https://github.com/mirianfsilva/titanic-kaggle-competition)\n",
    "\n",
    "- Keep praticing on Kaggle! \n",
    "\n",
    "- It's important that you improve your theorical backgroung too, undestanding what's every model does in the background. So I also recommend this Coursera Course, it's a good complement for your practices: [Machine Learning by Stanford University](https://www.coursera.org/learn/machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
