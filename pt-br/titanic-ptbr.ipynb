{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o a Machine Learning em uma Competi√ß√£o do Kaggle: Titanic\n",
    "\n",
    "<img src=\"https://github.com/mirianfsilva/titanic-kaggle-competition/blob/master/en-us/images/titanic.jpg?raw=true\" width=\"800\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 1: Introdu√ß√£o ao Kaggle\n",
    "    Criando sua conta no Kaggle e se inscrevendo na competi√ß√£o\n",
    "---\n",
    "- Crie sua conta no Kaggle e participe da competi√ß√£o em: [**Titanic: Machine Learning from Disaster**](https://www.kaggle.com/c/titanic).\n",
    "- Leia a descri√ß√£o e as informa√ß√µes sobre a competi√ß√£o. \n",
    "- Fa√ßa download do dataset que ser√° usado nesse projeto, que se encontra na p√°gina da competi√ß√£o. \n",
    "\n",
    "Vamos das inicio ao projeto!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 2: An√°lise Explorat√≥ria dos Dados (Exploratory Data Analysis - EDA)\n",
    "\n",
    "\n",
    "Importe as bibliotecas que inicialmente ser√£o utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary installations\n",
    "#python +3, pandas, pandas profiling\n",
    "%matplotlib inline\n",
    "! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) \n",
    "import matplotlib.pyplot as plt #plot our graphics and visualize our data\n",
    "import seaborn as sns #plot beautiful graphics :)\n",
    "import pandas_profiling as pp #pandas profiling analyse our entire dataset and facilate our work in a EDA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importe o conjunto de dados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Numbero dos dados de Treino = {}'.format(train_data.shape[0]))\n",
    "print('Numbero dos dados de Teste = {}\\n'.format(test_data.shape[0]))\n",
    "\n",
    "#target columns\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o dos Dados\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas Profiling Report\n",
    "\n",
    "report = pp.ProfileReport(train_data)\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota sobre as vari√°veis**\n",
    "\n",
    "_pclass_: Classe socioecon√¥mica/Status dos passageiros.\n",
    "- _1st_ = Upper\n",
    "- _2nd_ = Middle\n",
    "- _3rd_ = Lower\n",
    "\n",
    "_age_: Idade\n",
    "\n",
    "_sibsp_: Tipo familiar\n",
    "- _Sibling_ = irm√£o, irm√£\n",
    "- _Spouse_ = marido, esposa\n",
    "\n",
    "_parch_: O conjunto de dados define os relacionamento familiares da forma:\n",
    "- _Parent_ = mother, father\n",
    "- _Child_ = daughter, son, stepdaughter, stepson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exporte seu relat√≥rio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O comando a seguir ir√° exportar seu relat√≥rio em um arquivo html\n",
    "report.to_file(output_file=\"dataframe_titanic_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 3: Pr√©-processamento I\n",
    "    Analisando Dados Faltantes\n",
    "---\n",
    "\n",
    "**Important:** Dados Faltantes/Omissos s√£o dados que literalmente est√£o em falta no conjunto de dados e podem ser importantes para o resultado da an√°lise. Trabalhar com um dataset com dados faltantes √© um problema de grande relev√¢ncia na √°rea de An√°lise de Dados e esse problema pode ser originado devido a in√∫meras causas e fontes, como falhas no sistema de coleda dos dados, integra√ß√£o com diferentes fontes ao criar o dataset, etc., o ponto √© que devemos tomar cuidado para evitar vi√©s no resulta do que buscamos, devido a essa lacuna de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Descriptive statistics include those that summarize the central tendency, \n",
    "dispersion and shape of a dataset‚Äôs distribution, excluding NaN values.\n",
    "'''\n",
    "train_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de visualizar todo o nosso conjunto de dados, **verifique a descri√ß√£o acima ou a amostra dos dados em nosso relat√≥rio de dataframe**, voc√™ ver√° que existem certos pontos de dados rotulados com um `NaN`. Isso denota valores ausentes. Conjuntos de dados diferentes codificam valores ausentes de maneiras diferentes. √Äs vezes pode ser `9999`, outras vezes` 0` - porque os dados do mundo real podem ser muito confusos!\n",
    "\n",
    "**O objetivo aqui √© descobrir a melhor forma de processar os dados para que nosso modelo de aprendizado de m√°quina possa aprender com eles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√© processamento\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe os valores num√©ricos e categ√≥ricos separadamente:**\n",
    "\n",
    "Caracter√≠sticas num√©ricas: Idade, tarifa, SibSp, Parch.\n",
    "Caracter√≠sticas categ√≥ricas: sobrevivido, sexo, embarcado, Pclass.\n",
    "Caracter√≠sticas alfanum√©ricas (mas categ√≥ricas): Ingresso, Cabine.\n",
    "\n",
    "Pela vis√£o geral do relat√≥rio, clique na tab \"Warnings\" para ver mais:\n",
    "\n",
    "- Ingressos e Cabine s√£o caracter√≠sticas com alta cardinalidade e muitos valores diferenciados.\n",
    "- Idade e cabine tem muitos valores ausentes.\n",
    "- Nome e ID possuem valores √∫nicos.\n",
    "- SibSp, Parch e Fare tem muitos zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantas pessoas sobreviveram?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 2))\n",
    "sns.countplot(y =\"Survived\",palette=\"pastel\",data=train_data)\n",
    "plt.title(\"Not Survived vs Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**Feature Nome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Name and ID. We won't move forward using the name variable.\n",
    "train_data = train_data.drop([\"Name\"], axis=1)\n",
    "test_data = test_data.drop([\"Name\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Idade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "sns.boxplot(x=\"Survived\", y=\"Age\", palette=\"pastel\", data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Age. We have some missing values in Age, 117 missing, we won't move forward with this.\n",
    "train_data = train_data.drop([\"Age\"], axis = 1)\n",
    "test_data = test_data.drop([\"Age\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Ticket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See plot inside our report. Tickets vs frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Ticket. We won't use Ticket.\n",
    "train_data = train_data.drop([\"Ticket\"], axis=1)\n",
    "test_data = test_data.drop([\"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**Feature Cabine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See plot inside our report. Cabin vs frequency of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Cabin. Too many missing values, we won't move forward with this.\n",
    "train_data = train_data.drop([\"Cabin\"], axis=1)\n",
    "test_data = test_data.drop([\"Cabin\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 4: Pr√©-processamento II\n",
    "    Analisando Dados Faltantes\n",
    "---\n",
    "**Feature Embarque**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='Embarked', palette=\"pastel\", data=train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have 2 missing values in the feature embarked. We will Drop these 2 missing values only in the train set\n",
    "train_data = train_data.dropna(subset=[\"Embarked\"])\n",
    "\n",
    "'''\n",
    "Other option, is fill the 2 missing values with the place where the majority of people embarked \n",
    "According our histogram plotted in our report, Southampton is the most frequent\n",
    "replacing the missing values in the Embarked feature with S\n",
    "'''\n",
    "#train_data = train_data.fillna({\"Embarked\": \"S\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Sexo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sex Feature: map each Sex value to a numerical value\n",
    "#0 for male and 1 for female\n",
    "train_data[\"Sex\"] = np.where(train_data[\"Sex\"] == \"female\", 1, 0)\n",
    "test_data[\"Sex\"] = np.where(test_data[\"Sex\"] == \"female\", 1, 0)\n",
    "\n",
    "# Let's view the distribution of Sex in our dataset\n",
    "plt.figure(figsize=(20, 2))\n",
    "sns.countplot(y=\"Sex\", palette=\"pastel\", data=train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", palette=\"pastel\", kind=\"bar\", data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 5:  Pr√©-processamento III\n",
    "    Codificando Dados Categ√≥ricos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificando Features\n",
    "\n",
    "Documenta√ß√£o Pandas get dummies: [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "**Conjunto de dados de Treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical columns\n",
    "embarked_oh = pd.get_dummies(train_data[\"Embarked\"], prefix=\"embarked\")\n",
    "sex_oh = pd.get_dummies(train_data[\"Sex\"], prefix=\"sex\")\n",
    "plcass_oh = pd.get_dummies(train_data[\"Pclass\"], prefix=\"pclass\")\n",
    "\n",
    "# Combine the encoded columns\n",
    "train_data = pd.concat([train_data, \n",
    "                    embarked_oh, \n",
    "                    sex_oh, \n",
    "                    plcass_oh], axis=1)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original categorical columns (because now they've been encoded)\n",
    "train_data = train_data.drop([\"Pclass\", \"Sex\", \"Embarked\"], axis=1)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Conjunto de Dados de Teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical columns\n",
    "test_embarked_oh = pd.get_dummies(test_data[\"Embarked\"], prefix=\"embarked\")\n",
    "test_sex_oh = pd.get_dummies(test_data[\"Sex\"], prefix=\"sex\")\n",
    "test_plcass_oh = pd.get_dummies(test_data[\"Pclass\"], prefix=\"pclass\")\n",
    "\n",
    "# Combine the encoded columns\n",
    "test_data = pd.concat([test_data, \n",
    "                    test_embarked_oh, \n",
    "                    test_sex_oh, \n",
    "                    test_plcass_oh], axis=1)\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original categorical columns (because now they've been one hot encoded)\n",
    "test_data = test_data.drop([\"Pclass\", \"Sex\", \"Embarked\"], axis=1)\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 6: Dividindo os conjuntos de dados em treinamento e teste\n",
    "---\n",
    "\n",
    "Dividir o conjunto de dados em treinamento e teste √© muito comum, e voc√™ far√° isso em in√∫meras ocasi√µes. Mesmo que neste problema atual, tenhamos nosso treinamento e teste em arquivos csvs separadamente, usaremos essa t√©cnica em nosso conjunto de dados de treinamento, para que voc√™ possa se acostumar com esse procedimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_test_split**: O primeiro argumento ser√° o `feature data`, o segundo o` target or labels`. O argumento `test_size` especifica qual propor√ß√£o dos dados originais √© usada para o conjunto de teste. Por √∫ltimo, o kward `random_state` define uma semente para o gerador de n√∫meros aleat√≥rios que divide os dados em treino e teste.\n",
    "\n",
    "Dividindo os dados de treinamento, usaremos parte de nossos dados de treinamento (30% neste caso) para testar a precis√£o de nossos diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train_data[\"Survived\"] #target\n",
    "X = train_data.drop([\"Survived\", \"PassengerId\"], axis=1) #train predictors\n",
    "\n",
    "#train_test_split(predictors, target, test_size = 0.22, random_state = 0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state= 21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our target is a unique vector with one coordinate\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 7: Construindo nossos modelos de aprendizado de m√°quina\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "A regress√£o log√≠stica √© uma t√©cnica estat√≠stica que tem como objetivo produzir, a partir de um conjunto de observa√ß√µes, um modelo que permita a predi√ß√£o de valores tomados por uma vari√°vel categ√≥rica, frequentemente bin√°ria, a partir de uma s√©rie de vari√°veis explicativas cont√≠nuas e/ou bin√°rias. Trata-se de um modelo de regress√£o para vari√°veis dependentes ou de resposta binomialmente distribu√≠das. √â √∫til para modelar a probabilidade de um evento ocorrer como fun√ß√£o de outros factores, como o problema do Titanic desse projeto. √â um modelo linear generalizado que usa como fun√ß√£o de liga√ß√£o a fun√ß√£o logit.\n",
    "\n",
    "Reference: [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "acc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "acc_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "O aprendizado da √°rvore de decis√£o √© uma das abordagens de modelagem preditiva usadas em estat√≠stica, minera√ß√£o de dados e aprendizado de m√°quina. Ele usa uma √°rvore de decis√£o (como um modelo preditivo) para ir de observa√ß√µes sobre um item (representado nos ramos) para conclus√µes sobre o valor alvo - target - do item (representado nas folhas). Os modelos de √°rvore em que a vari√°vel de destino pode assumir um conjunto discreto de valores s√£o chamados de √°rvores de classifica√ß√£o; nessas estruturas de √°rvore, as folhas representam r√≥tulos de classe e os ramos representam conjun√ß√µes de features que levam a esses r√≥tulos de classe. As √°rvores de decis√£o nas quais a vari√°vel de destino pode assumir valores cont√≠nuos (normalmente n√∫meros reais) s√£o chamadas de √°rvores de regress√£o. As √°rvores de decis√£o est√£o entre os algoritmos de aprendizado de m√°quina mais populares devido √† sua inteligibilidade e simplicidade. \n",
    "\n",
    "Reference: [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_val)\n",
    "acc_dt = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "acc_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Adicionais\n",
    "---\n",
    "\n",
    "Se voc√™ quiser testar outros modelos e comparar seu desempenho com os dois que j√° usamos. Abaixo voc√™ encontra esses modelos j√° declarados. \n",
    "Sinta-se √† vontade para test√°-los tamb√©m, execute para ver os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "acc_rf = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(\"Random Forest Accuracy\",acc_rf)\n",
    "\n",
    "\n",
    "#KNN | K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_val)\n",
    "acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(\"K-Nearest Neighbors Accuracy\",acc_knn)\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_val)\n",
    "acc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(\"Support Vector Machine\", acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 8: Realizando a submiss√£o do projeto no Kaggle\n",
    "---\n",
    "\n",
    "Agora que voc√™ avaliou a perfomance do seu modelo, vamos criar um arquivo csv para a submiss√£o na competi√ß√£o do Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original test dataset\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(test_data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.fillna(0)\n",
    "pd.isnull(test_data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predi√ß√£o Final e Gera√ß√£o do Arquivo de Submiss√£o no Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "#set the output as a dataframe and convert to csv file named submission.csv\n",
    "submission[\"PassengerId\"] = test_data[\"PassengerId\"]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(\"PassengerId\", axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(test_data)\n",
    "submission[\"Survived\"] =  predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicas e Materiais de Estudo Recomendados: \n",
    "\n",
    "- [Seaborn: Statistical Data Visualization](https://seaborn.pydata.org/index.html)\n",
    "\n",
    "- Recomenda√ß√£o que pode ser interessante, caso queira ver uma an√°lise diferente dos mesmos dados do Titanic: [Titanic - A Data Science Approach](https://www.kaggle.com/pedrodematos/titanic-a-complete-data-science-approach)\n",
    "\n",
    "- O notebook completo desse curso, voc√™ encontra na conta do github da instrutora. Se voc√™ desehar realizar melhorias, sinta-se a vontade para compartilhar com a instrutora. \n",
    "[Project on Github](https://github.com/mirianfsilva/titanic-kaggle-competition)\n",
    "\n",
    "- Continue praticando no Kaggle! \n",
    "\n",
    "- Esse √© um projeto pr√°tico, mas √© importante que voc√™ tamb√©m melhore seu background teorico em aprendizagem de m√°quina, entendendo como cada modelo funciona por tr√°s do c√≥digo. Ent√£o recomento esse curso do Coursera da Universidade de Stanford, que definitivamente √© um excelente come√ßo para quem √© iniciante, e √© um bom complemento para suas pr√°ticas: [Machine Learning by Stanford University](https://www.coursera.org/learn/machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
