{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o a Machine Learning em uma Competi√ß√£o do Kaggle: Titanic\n",
    "\n",
    "<img src=\"images/titanic.jpg\" width=\"800\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 1: Introdu√ß√£o ao Kaggle\n",
    "    Criando sua conta no Kaggle e se inscrevendo na competi√ß√£o\n",
    "---\n",
    "- Crie sua conta no Kaggle e participe da competi√ß√£o em: [**Titanic: Machine Learning from Disaster**](https://www.kaggle.com/c/titanic).\n",
    "- Leia a descri√ß√£o e as informa√ß√µes sobre a competi√ß√£o. \n",
    "- Fa√ßa download do dataset que ser√° usado nesse projeto, que se encontra na p√°gina da competi√ß√£o. \n",
    "\n",
    "Vamos das inicio ao projeto!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 2: An√°lise Explorat√≥ria dos Dados (Exploratory Data Analysis - EDA)\n",
    "\n",
    "\n",
    "Importe as bibliotecas que inicialmente ser√£o utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary installations\n",
    "#python +3, pandas, pandas profiling\n",
    "%matplotlib inline\n",
    "%pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) \n",
    "import matplotlib.pyplot as plt #plot our graphics and visualize our data\n",
    "import seaborn as sns #plot beautiful graphics :)\n",
    "import pandas_profiling as pp #pandas profiling analyse our entire dataset and facilate our work in a EDA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importe o conjunto de dados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Numbero dos dados de Treino = {}'.format(train_data.shape[0]))\n",
    "print('Numbero dos dados de Teste = {}\\n'.format(test_data.shape[0]))\n",
    "\n",
    "#target columns\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o dos Dados\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas Profiling Report\n",
    "\n",
    "report = pp.ProfileReport(train_data)\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota sobre as vari√°veis**\n",
    "\n",
    "_pclass_: Classe socioecon√¥mica/Status dos passageiros.\n",
    "- _1st_ = Upper\n",
    "- _2nd_ = Middle\n",
    "- _3rd_ = Lower\n",
    "\n",
    "_age_: Idade\n",
    "\n",
    "_sibsp_: Tipo familiar\n",
    "- _Sibling_ = irm√£o, irm√£\n",
    "- _Spouse_ = marido, esposa\n",
    "\n",
    "_parch_: O conjunto de dados define os relacionamento familiares da forma:\n",
    "- _Parent_ = mother, father\n",
    "- _Child_ = daughter, son, stepdaughter, stepson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exporte seu relat√≥rio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O comando a seguir ir√° exportar seu relat√≥rio em um arquivo html\n",
    "report.to_file(output_file=\"dataframe_titanic_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 3: Pr√©-processamento I\n",
    "    Analisando Dados Faltantes\n",
    "---\n",
    "\n",
    "**Important:** Dados Faltantes/Omissos s√£o dados que est√£o faltando no conjunto de dados e podem ser importantes para o resultado da an√°lise. Trabalhar com um conjunto de dados, com dados faltantes √© um problema de grande relev√¢ncia na √°rea de An√°lise de Dados e pode ser originado devido a in√∫meras causas e fontes\n",
    "\n",
    "Missing data is information that is missing from a database and could be important for the result of an analysis. Working with a dataset with missing values is a problem of great relevance at the time of data analysis and can originate from different sources, such as failures in the collection system, problems with the integration of different sources, etc., the point is: we must be careful to avoid bias in the results we seek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Descriptive statistics include those that summarize the central tendency, \n",
    "dispersion and shape of a dataset‚Äôs distribution, excluding NaN values.\n",
    "'''\n",
    "train_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visualized our entire dataset, **check the describe above or the Sample in our dataframe report**, you see that there are certain data points labeled with a `NaN`. These denote missing values. Different datasets encode missing values in different ways. Sometimes it may be a `9999`, other times a`0` - because real world data can be very messy!\n",
    "\n",
    "\n",
    "**The goal here is to figure out how best to process the data so our machine learning model can learn from it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at numeric and categorical values separately:**\n",
    "\n",
    "Numerical Features: Age, Fare, SibSp, Parch.\n",
    "\n",
    "Categorical Features: Survived, Sex, Embarked, Pclass.\n",
    "\n",
    "Alphanumeric Features (but categorical): Ticket, Cabin.\n",
    "\n",
    "In our overview report, click on the tab \"Warnings\": \n",
    "\n",
    "- Tickets and Cabin are features with a high cardinality, and a lot of distinc values. \n",
    "- Age and Cabin has a lot of missing values.\n",
    "- Name and ID has unique values.\n",
    "- SibSp, Parch and Fare has a lot of zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many people survived?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 2))\n",
    "sns.countplot(y =\"Survived\",palette=\"pastel\",data=train_data)\n",
    "plt.title(\"Not Survived vs Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**Feature Name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Name and ID. We won't move forward using the name variable.\n",
    "train_data = train_data.drop([\"Name\"], axis=1)\n",
    "test_data = test_data.drop([\"Name\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "sns.boxplot(x=\"Survived\", y=\"Age\", palette=\"pastel\", data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Age. We have some missing values in Age, 117 missing, we won't move forward with this.\n",
    "train_data = train_data.drop([\"Age\"], axis = 1)\n",
    "test_data = test_data.drop([\"Age\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Ticket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See plot inside our report. Tickets vs frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Ticket. We won't use Ticket.\n",
    "train_data = train_data.drop([\"Ticket\"], axis=1)\n",
    "test_data = test_data.drop([\"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**Feature Cabin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See plot inside our report. Cabin vs frequency of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature: Cabin. Too many missing values, we won't move forward with this.\n",
    "train_data = train_data.drop([\"Cabin\"], axis=1)\n",
    "test_data = test_data.drop([\"Cabin\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 4: Pr√©-processamento II\n",
    "    Analisando Dados Faltantes\n",
    "---\n",
    "**Feature Embarked**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='Embarked', palette=\"pastel\", data=train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have 2 missing values in the feature embarked. We will Drop these 2 missing values only in the train set\n",
    "train_data = train_data.dropna(subset=[\"Embarked\"])\n",
    "\n",
    "'''\n",
    "Other option, is fill the 2 missing values with the place where the majority of people embarked \n",
    "According our histogram plotted in our report, Southampton is the most frequent\n",
    "replacing the missing values in the Embarked feature with S\n",
    "'''\n",
    "#train_data = train_data.fillna({\"Embarked\": \"S\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Feature Sex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sex Feature: map each Sex value to a numerical value\n",
    "#0 for male and 1 for female\n",
    "train_data[\"Sex\"] = np.where(train_data[\"Sex\"] == \"female\", 1, 0)\n",
    "test_data[\"Sex\"] = np.where(test_data[\"Sex\"] == \"female\", 1, 0)\n",
    "\n",
    "# Let's view the distribution of Sex in our dataset\n",
    "plt.figure(figsize=(20, 2))\n",
    "sns.countplot(y=\"Sex\", palette=\"pastel\", data=train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", palette=\"pastel\", kind=\"bar\", data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 5:  Pr√©-processamento III\n",
    "    Codificando Dados Categ√≥ricos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding\n",
    "\n",
    "Documentation: [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "**Train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical columns\n",
    "embarked_oh = pd.get_dummies(train_data[\"Embarked\"], prefix=\"embarked\")\n",
    "sex_oh = pd.get_dummies(train_data[\"Sex\"], prefix=\"sex\")\n",
    "plcass_oh = pd.get_dummies(train_data[\"Pclass\"], prefix=\"pclass\")\n",
    "\n",
    "# Combine the encoded columns\n",
    "train_data = pd.concat([train_data, \n",
    "                    embarked_oh, \n",
    "                    sex_oh, \n",
    "                    plcass_oh], axis=1)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original categorical columns (because now they've been encoded)\n",
    "train_data = train_data.drop([\"Pclass\", \"Sex\", \"Embarked\"], axis=1)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical columns\n",
    "test_embarked_oh = pd.get_dummies(test_data[\"Embarked\"], prefix=\"embarked\")\n",
    "test_sex_oh = pd.get_dummies(test_data[\"Sex\"], prefix=\"sex\")\n",
    "test_plcass_oh = pd.get_dummies(test_data[\"Pclass\"], prefix=\"pclass\")\n",
    "\n",
    "# Combine the encoded columns\n",
    "test_data = pd.concat([test_data, \n",
    "                    test_embarked_oh, \n",
    "                    test_sex_oh, \n",
    "                    test_plcass_oh], axis=1)\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original categorical columns (because now they've been one hot encoded)\n",
    "test_data = test_data.drop([\"Pclass\", \"Sex\", \"Embarked\"], axis=1)\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 6: Dividindo os conjuntos de dados em treinamento e teste\n",
    "---\n",
    "\n",
    "Split the dataset into training and testing is very common, and you will do it on countless occasions. Even though in this current problem, we have our training and test csv separately, we will use this technique in our training dataset, so we can get used to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_test_split**: The first argument will be the `feature data`, the second the `target or labels`. The `test_size` keyword argument specifies what proportion of the original data is used for the test set. Lastly, the `random_state` kward sets a seed for the random number generator that splits the data into trains and test.\n",
    "\n",
    "Splitting the Training Data we will use part of our training data (30% in this case) to test the accuracy of our different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train_data[\"Survived\"] #target\n",
    "X = train_data.drop([\"Survived\", \"PassengerId\"], axis=1) #train predictors\n",
    "\n",
    "#train_test_split(predictors, target, test_size = 0.22, random_state = 0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state= 21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our target is a unique vector with one coordinate\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 7: Construindo nossos modelos de aprendizado de m√°quina\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "Logistic regression measures the relationship between the categorical dependent variable _(feature)_ and one or more independent variables _(features)_ by estimating probabilities using a logistic function, which is the cumulative distribution function of logistic distribution. \n",
    "\n",
    "Reference: [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "acc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "acc_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning. It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Decision trees are among the most popular machine learning algorithms given their intelligibility and simplicity\n",
    "\n",
    "Reference: [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_val)\n",
    "acc_dt = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "acc_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aditional Models\n",
    "---\n",
    "\n",
    "\n",
    "If you want to test other models, and compare their performance with the two we already use. Below you find these models already declared. Feel free to also test them. Chance the cell type, `raw` for `code`, and run to see the results. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "acc_rf = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(\"Random Forest Accuracy\",acc_rf)\n",
    "\n",
    "\n",
    "#KNN | K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_val)\n",
    "acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(\"K-Nearest Neighbors Accuracy\",acc_knn)\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_val)\n",
    "acc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(\"Support Vector Machine\", acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tarefa 8: Realizando a submiss√£o do projeto no Kaggle\n",
    "---\n",
    "\n",
    "Agora que voc√™ avaliou a perfomance do seu modelo, vamos criar um arquivo csv para a submiss√£o na competi√ß√£o do Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original test dataset\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(test_data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.fillna(0)\n",
    "pd.isnull(test_data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predi√ß√£o Final e Gera√ß√£o do Arquivo de Submiss√£o no Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "#set the output as a dataframe and convert to csv file named submission.csv\n",
    "submission[\"PassengerId\"] = test_data[\"PassengerId\"]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(\"PassengerId\", axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(test_data)\n",
    "submission[\"Survived\"] =  predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicas e Materiais de Estudo Recomendados: \n",
    "\n",
    "- [Seaborn: Statistical Data Visualization](https://seaborn.pydata.org/index.html)\n",
    "\n",
    "- Recomenda√ß√£o que pode ser interessante, caso queira ver uma an√°lise diferente dos mesmos dados do Titanic: [Titanic - A Data Science Approach](https://www.kaggle.com/pedrodematos/titanic-a-complete-data-science-approach)\n",
    "\n",
    "- O notebook completo desse curso, voc√™ encontra na conta do github da instrutora. Se voc√™ desehar realizar melhorias, sinta-se a vontade para compartilhar com a instrutora. \n",
    "[Project on Github](https://github.com/mirianfsilva/titanic-kaggle-competition)\n",
    "\n",
    "- Continue praticando no Kaggle! \n",
    "\n",
    "- Esse √© um projeto pr√°tico, mas √© importante que voc√™ tamb√©m melhore seu background teorico em aprendizagem de m√°quina, entendendo como cada modelo funciona por tr√°s do c√≥digo. Ent√£o recomento esse curso do Coursera da Universidade de Stanford, que definitivamente √© um excelente come√ßo para quem √© iniciante, e √© um bom complemento para suas pr√°ticas: [Machine Learning by Stanford University](https://www.coursera.org/learn/machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
